{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ebf629e",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12886c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dbcc7f",
   "metadata": {},
   "source": [
    "### 1a. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a8a65c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('modelingdf.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0566c373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Sex</th>\n",
       "      <th>GeneralHealth</th>\n",
       "      <th>PhysicalHealthDays</th>\n",
       "      <th>MentalHealthDays</th>\n",
       "      <th>LastCheckup</th>\n",
       "      <th>ExerciseLast30days</th>\n",
       "      <th>SleepTime</th>\n",
       "      <th>HadAngina</th>\n",
       "      <th>HadStroke</th>\n",
       "      <th>...</th>\n",
       "      <th>EcigUsage</th>\n",
       "      <th>HadCovid</th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>RaceEthnicityGroup</th>\n",
       "      <th>AgeGroup5yrs</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DrinkOccasionsPerDay</th>\n",
       "      <th>Smoked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1.60</td>\n",
       "      <td>68.04</td>\n",
       "      <td>26.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.57</td>\n",
       "      <td>63.50</td>\n",
       "      <td>25.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.65</td>\n",
       "      <td>63.50</td>\n",
       "      <td>23.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.57</td>\n",
       "      <td>53.98</td>\n",
       "      <td>21.77</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1.80</td>\n",
       "      <td>84.82</td>\n",
       "      <td>26.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   State  Sex  GeneralHealth  PhysicalHealthDays  MentalHealthDays  \\\n",
       "1      1    0              5                 0.0               0.0   \n",
       "2      1    0              4                 2.0               3.0   \n",
       "3      1    0              5                 0.0               0.0   \n",
       "4      1    0              2                 2.0               0.0   \n",
       "5      1    1              1                 1.0               0.0   \n",
       "\n",
       "   LastCheckup  ExerciseLast30days  SleepTime  HadAngina  HadStroke  ...  \\\n",
       "1            0                 0.0        6.0        0.0        0.0  ...   \n",
       "2            1                 1.0        5.0        0.0        0.0  ...   \n",
       "3            1                 1.0        7.0        0.0        0.0  ...   \n",
       "4            1                 1.0        9.0        0.0        0.0  ...   \n",
       "5            1                 0.0        7.0        0.0        1.0  ...   \n",
       "\n",
       "   EcigUsage  HadCovid  HeartDisease  RaceEthnicityGroup  AgeGroup5yrs  \\\n",
       "1        0.0       0.0             0                   0            12   \n",
       "2        0.0       1.0             0                   0             7   \n",
       "3        0.0       0.0             0                   0             9   \n",
       "4        0.0       0.0             0                   0             4   \n",
       "5        0.0       0.0             1                   0            12   \n",
       "\n",
       "   Height  Weight    BMI  DrinkOccasionsPerDay  Smoked  \n",
       "1    1.60   68.04  26.57                   0.0     0.0  \n",
       "2    1.57   63.50  25.61                   0.0     0.0  \n",
       "3    1.65   63.50  23.30                   0.0     1.0  \n",
       "4    1.57   53.98  21.77                  10.0     0.0  \n",
       "5    1.80   84.82  26.08                   0.0     0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38cdf365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356169 entries, 1 to 445131\n",
      "Data columns (total 26 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   State                 356169 non-null  int64  \n",
      " 1   Sex                   356169 non-null  int64  \n",
      " 2   GeneralHealth         356169 non-null  int64  \n",
      " 3   PhysicalHealthDays    356169 non-null  float64\n",
      " 4   MentalHealthDays      356169 non-null  float64\n",
      " 5   LastCheckup           356169 non-null  int64  \n",
      " 6   ExerciseLast30days    355543 non-null  float64\n",
      " 7   SleepTime             356169 non-null  float64\n",
      " 8   HadAngina             355160 non-null  float64\n",
      " 9   HadStroke             355376 non-null  float64\n",
      " 10  HadCOPD               354858 non-null  float64\n",
      " 11  HadKidneyDisease      355028 non-null  float64\n",
      " 12  HadArthritis          354457 non-null  float64\n",
      " 13  HadDiabetes           355656 non-null  float64\n",
      " 14  Deaf                  355111 non-null  float64\n",
      " 15  DifficultyWalking     355142 non-null  float64\n",
      " 16  EcigUsage             354957 non-null  float64\n",
      " 17  HadCovid              355307 non-null  float64\n",
      " 18  HeartDisease          356169 non-null  int64  \n",
      " 19  RaceEthnicityGroup    356169 non-null  int64  \n",
      " 20  AgeGroup5yrs          356169 non-null  int64  \n",
      " 21  Height                356169 non-null  float64\n",
      " 22  Weight                356169 non-null  float64\n",
      " 23  BMI                   356169 non-null  float64\n",
      " 24  DrinkOccasionsPerDay  356169 non-null  float64\n",
      " 25  Smoked                353900 non-null  float64\n",
      "dtypes: float64(19), int64(7)\n",
      "memory usage: 73.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41592fc",
   "metadata": {},
   "source": [
    "## 2. Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c970e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features + Target datasets\n",
    "X = df.drop(columns =['HeartDisease'], axis = 1)\n",
    "y = df['HeartDisease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5cedb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafdd94c",
   "metadata": {},
   "source": [
    "## Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed5f095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_2_score(y_true, y_pred):\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    beta = 2\n",
    "    return (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae44d4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    beta_2 = beta_2_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'acc': acc,\n",
    "        'prec': prec,\n",
    "        'rec': rec,\n",
    "        'f1': f1,\n",
    "        'beta_2' :beta_2,\n",
    "        'auc': auc,\n",
    "        'cm': cm\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81a965df",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    break\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bc5643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3b9a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler(),\n",
    "    'MaxAbsScaler': MaxAbsScaler()\n",
    "}\n",
    "\n",
    "# Dictionary to store evaluation results\n",
    "results_rf = {}\n",
    "\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    # Define the pipeline with the current scaler\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values\n",
    "        ('scaler', scaler),  # Apply the current scaler\n",
    "        ('smote', SMOTE(random_state=42)),  # Apply SMOTE for class balancing\n",
    "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))  # KNN classifier\n",
    "    ])\n",
    "    \n",
    "    # Fit the pipeline on training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    accuracy = report['accuracy']\n",
    "    recall = report['macro avg']['recall']  # Use 'macro avg' to get the average recall\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    beta_2 = beta_2_score(y_test, y_pred)  # Calculate Beta=2 score\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    ROCAUC = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Store results\n",
    "    results_rf[scaler_name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'beta_2_score': beta_2,\n",
    "        'precision': precision,\n",
    "        'confusion_matrix': cm,\n",
    "        'ROC AUC Score' :  ROCAUC\n",
    "    }\n",
    "\n",
    "# Print the results\n",
    "for scaler_name, metrics in results_rf.items():\n",
    "    print(f\"{scaler_name}: Accuracy = {metrics['accuracy']:.4f}, Recall = {metrics['recall']:.4f}, F1 Score = {metrics['f1_score']:.4f}, Beta=2 Score = {metrics['beta_2_score']:.4f}, Precision = {metrics['precision']:.4f}, ROC AUC Score = {metrics['ROC AUC Score']:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{metrics['confusion_matrix']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1568384",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler(),\n",
    "    'MaxAbsScaler': MaxAbsScaler()\n",
    "}\n",
    "\n",
    "# Dictionary to store evaluation results\n",
    "results_log = {}\n",
    "\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    # Define the pipeline with the current scaler\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values\n",
    "        ('scaler', scaler),  # Apply the current scaler\n",
    "        ('smote', SMOTE(random_state=42)),  # Apply SMOTE for class balancing\n",
    "        ('classifier', LogisticRegression(random_state=42))  # KNN classifier\n",
    "    ])\n",
    "    \n",
    "    # Fit the pipeline on training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    accuracy = report['accuracy']\n",
    "    recall = report['macro avg']['recall']  # Use 'macro avg' to get the average recall\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    beta_2 = beta_2_score(y_test, y_pred)  # Calculate Beta=2 score\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    ROCAUC = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Store results\n",
    "    results_log[scaler_name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'beta_2_score': beta_2,\n",
    "        'precision': precision,\n",
    "        'confusion_matrix': cm,\n",
    "        'ROC AUC Score' :  ROCAUC\n",
    "    }\n",
    "\n",
    "# Print the results\n",
    "for scaler_name, metrics in results_log.items():\n",
    "    print(f\"{scaler_name}: Accuracy = {metrics['accuracy']:.4f}, Recall = {metrics['recall']:.4f}, F1 Score = {metrics['f1_score']:.4f}, Beta=2 Score = {metrics['beta_2_score']:.4f}, Precision = {metrics['precision']:.4f}, ROC AUC Score = {metrics['ROC AUC Score']:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{metrics['confusion_matrix']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce0c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler(),\n",
    "    'MaxAbsScaler': MaxAbsScaler()\n",
    "}\n",
    "\n",
    "# Dictionary to store evaluation results\n",
    "results_log = {}\n",
    "\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    # Define the pipeline with the current scaler\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values\n",
    "        ('scaler', scaler),  # Apply the current scaler\n",
    "        ('smote', SMOTE(random_state=42)),  # Apply SMOTE for class balancing\n",
    "        ('classifier', LogisticRegression(random_state=42))  # KNN classifier\n",
    "    ])\n",
    "    \n",
    "    # Fit the pipeline on training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    accuracy = report['accuracy']\n",
    "    recall = report['macro avg']['recall']  # Use 'macro avg' to get the average recall\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    beta_2 = beta_2_score(y_test, y_pred)  # Calculate Beta=2 score\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    ROCAUC = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Store results\n",
    "    results_log[scaler_name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'beta_2_score': beta_2,\n",
    "        'precision': precision,\n",
    "        'confusion_matrix': cm,\n",
    "        'ROC AUC Score' :  ROCAUC\n",
    "    }\n",
    "\n",
    "# Print the results\n",
    "for scaler_name, metrics in results_log.items():\n",
    "    print(f\"{scaler_name}: Accuracy = {metrics['accuracy']:.4f}, Recall = {metrics['recall']:.4f}, F1 Score = {metrics['f1_score']:.4f}, Beta=2 Score = {metrics['beta_2_score']:.4f}, Precision = {metrics['precision']:.4f}, ROC AUC Score = {metrics['ROC AUC Score']:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{metrics['confusion_matrix']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72cb1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler(),\n",
    "    'MaxAbsScaler': MaxAbsScaler()\n",
    "}\n",
    "\n",
    "# Dictionary to store evaluation results\n",
    "results_xg = {}\n",
    "\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    # Define the pipeline with the current scaler\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values\n",
    "        ('scaler', scaler),  # Apply the current scaler\n",
    "        ('smote', SMOTE(random_state=42)),  # Apply SMOTE for class balancing\n",
    "        ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))  # XGBoost classifier\n",
    "    ])\n",
    "    \n",
    "    # Fit the pipeline on training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    accuracy = report['accuracy']\n",
    "    recall = report['macro avg']['recall']  # Use 'macro avg' to get the average recall\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    beta_2 = beta_2_score(y_test, y_pred)  # Calculate Beta=2 score\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    ROCAUC = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Store results\n",
    "    results_xg[scaler_name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'beta_2_score': beta_2,\n",
    "        'precision': precision,\n",
    "        'confusion_matrix': cm,\n",
    "        'ROC AUC Score' :  ROCAUC\n",
    "    }\n",
    "\n",
    "# Print the results\n",
    "for scaler_name, metrics in results_xg.items():\n",
    "    print(f\"{scaler_name}: Accuracy = {metrics['accuracy']:.4f}, Recall = {metrics['recall']:.4f}, F1 Score = {metrics['f1_score']:.4f}, Beta=2 Score = {metrics['beta_2_score']:.4f}, Precision = {metrics['precision']:.4f}, ROC AUC Score = {metrics['ROC AUC Score']:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{metrics['confusion_matrix']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb15a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "print('Accuracy:', _eval['acc'])\n",
    "print('Precision:', _eval['prec'])\n",
    "print('Recall:', _eval['rec'])\n",
    "print('F1 Score:', _eval['f1'])\n",
    "print('beta_2', _eval['beta_2'])\n",
    "print('Area Under Curve:', _eval['auc'])\n",
    "print('Confusion Matrix:\\n', _eval['cm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9c594c",
   "metadata": {},
   "source": [
    "I think we are going to go with Robust Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3b6de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "print('Best Threshold based on F1 Score:', best_threshold)\n",
    "\n",
    "# Apply best threshold\n",
    "y_pred_int = (y_pred_proba >= best_threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8f0d6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best Parameters: {'classifier__C': 0.001, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "Best Cross-Validation ROC AUC Score: 0.9392\n",
      "Test ROC AUC Score: 0.9372\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95     64524\n",
      "           1       0.55      0.78      0.65      6710\n",
      "\n",
      "    accuracy                           0.92     71234\n",
      "   macro avg       0.77      0.86      0.80     71234\n",
      "weighted avg       0.94      0.92      0.93     71234\n",
      "\n",
      "f1_score: 0.648938795656466\n",
      "beta_2: 0.7236226539710496\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'classifier__C': [0.001],               # Regularization strength\n",
    "    'classifier__penalty': [ 'l2'],    # Type of regularization\n",
    "    'classifier__solver': [ 'saga']  # Optimization algorithm\n",
    "}\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values\n",
    "    ('scaler', MaxAbsScaler()),  # Apply StandardScaler\n",
    "    ('smote', SMOTE(random_state=42)),  # Apply SMOTE for class balancing\n",
    "    ('classifier', LogisticRegression(random_state=42))  # Logistic Regression classifier\n",
    "])\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=2  # Print progress\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Best Cross-Validation ROC AUC Score: {best_score:.4f}')\n",
    "\n",
    "# Evaluate on the test set\n",
    "best_log_reg_model = grid_search.best_estimator_\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "y_pred_proba = grid_search.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "beta_2 = beta_2_score(y_test, y_pred)\n",
    "print(f'Test ROC AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}')\n",
    "print(f'Classification Report:\\n{classification_report(y_test, y_pred)}')\n",
    "print(f'f1_score: {f1}')\n",
    "print(f'beta_2: {beta_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca66e05",
   "metadata": {},
   "source": [
    "from xgboost import XGBClassifier\n",
    "# Define the parameter distribution\n",
    "param_dist = { \n",
    "    #'classifier__n_estimators': np.arange(50, 201, 50),           # Number of boosting rounds, 100\n",
    "    #'classifier__learning_rate': np.logspace(-3, -1, 5),          # Learning rate, 0.1\n",
    "    #'classifier__max_depth': np.arange(3, 10, 1),                 # Maximum depth of a tree, 9 \n",
    "    #'classifier__subsample': np.linspace(0.6, 1.0, 5),            # Subsample ratio of the training instance,0.6\n",
    "    #'classifier__colsample_bytree': np.linspace(0.6, 1.0, 5),     # Subsample ratio of columns when constructing each tree, 0.6\n",
    "    'classifier__gamma': np.linspace(0, 0.4, 5)                   # Minimum loss reduction required to make a further partition,0.1\n",
    "}\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values\n",
    "    ('scaler', RobustScaler()),  # Apply StandardScaler\n",
    "    ('smote', SMOTE(random_state=42)),  # Apply SMOTE for class balancing\n",
    "    ('classifier', XGBClassifier(n_estimators = 100,learning_rate= 0.1,max_depth = 9,subsample = 0.6,colsample_bytree = 0.6, use_label_encoder=False, eval_metric='logloss', random_state=42))  # XGBoost classifier\n",
    "])\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,  # Number of parameter settings to sample\n",
    "    scoring='roc_auc',\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=2,  # Print progress\n",
    "    random_state=42  # Seed for reproducibility\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Best Cross-Validation ROC AUC Score: {best_score:.4f}')\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = random_search.best_estimator_.predict(X_test)\n",
    "y_pred_proba = random_search.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "print(f'Test ROC AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}')\n",
    "print(f'Classification Report:\\n{classification_report(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2a9034d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imdan\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 1 is smaller than n_iter=30. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imdan\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [03:45:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {}\n",
      "Best Cross-Validation Recall: 0.7022\n",
      "Test Recall: 0.7001\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     64524\n",
      "           1       0.85      0.70      0.77      6710\n",
      "\n",
      "    accuracy                           0.96     71234\n",
      "   macro avg       0.91      0.84      0.87     71234\n",
      "weighted avg       0.96      0.96      0.96     71234\n",
      "\n",
      "f1_score: 0.7670204081632653\n",
      "beta_2: 0.7254478072884495\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# Define the parameter distribution\n",
    "param_dist = { \n",
    "    #'classifier__n_estimators': np.arange(50, 201, 50),           # Number of boosting rounds, 200\n",
    "    #'classifier__learning_rate': np.logspace(-3, -1, 5),          # Learning rate, 0.1\n",
    "    #'classifier__max_depth': np.arange(3, 10, 1),                 # Maximum depth of a tree, 9 \n",
    "    #'classifier__subsample': np.linspace(0.6, 1.0, 5),            # Subsample ratio of the training instance,0.6\n",
    "    #'classifier__colsample_bytree': np.linspace(0.6, 1.0, 5),     # Subsample ratio of columns when constructing each tree, 0.6\n",
    "    #'classifier__gamma': np.linspace(0, 0.4, 5)                   # Minimum loss reduction required to make a further partition,0.1\n",
    "}\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values\n",
    "    ('scaler', MaxAbsScaler()),  # Apply StandardScaler\n",
    "    ('smote', SMOTE(random_state=42)),  # Apply SMOTE for class balancing\n",
    "    ('classifier', XGBClassifier(n_estimators =200,learning_rate = 0.01,max_depth = 6, subsample=0.7,colsample_bytree=0.6\n",
    "                                 ,use_label_encoder=False,gamma= 0.1, eval_metric='logloss', random_state=42))  # XGBoost classifier\n",
    "])\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,  # Number of parameter settings to sample\n",
    "    scoring='recall',\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=2,  # Print progress\n",
    "    random_state=42  # Seed for reproducibility\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Best Cross-Validation Recall: {best_score:.4f}')\n",
    "\n",
    "# Evaluate on the test set\n",
    "best_xgb_model = random_search.best_estimator_\n",
    "y_pred = random_search.best_estimator_.predict(X_test)\n",
    "y_pred_proba = random_search.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "print(f'Test Recall: {recall_score(y_test, y_pred):.4f}')\n",
    "print(f'Classification Report:\\n{classification_report(y_test, y_pred)}')\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "beta_2 = beta_2_score(y_test, y_pred)\n",
    "print(f'f1_score: {f1}')\n",
    "print(f'beta_2: {beta_2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e539420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values\n",
    "    ('scaler', MaxAbsScaler()),  # Apply StandardScaler\n",
    "    ('smote', SMOTE(random_state=42)),  # Apply SMOTE for class balancing\n",
    "    ('classifier', XGBClassifier(n_estimators =100,learning_rate = 0.01,max_depth = 6, subsample=0.7,colsample_bytree=0.6\n",
    "                                 ,use_label_encoder=False,gamma= 0.1, eval_metric='logloss', random_state=42))  # XGBoost classifier\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "beta_2 = beta_2_score(y_test, y_pred)\n",
    "\n",
    "print(f'f1_score: {f1}')\n",
    "print(f'beta_2: {beta_2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d335568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'classifier__n_neighbors': [100, 200],\n",
    "    'classifier__weights': ['distance'],\n",
    "    'classifier__p': [1]  # 1 for Manhattan distance, 2 for Euclidean distance\n",
    "}\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('scaler', MaxAbsScaler()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=2  # Print progress\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f'Best Parameters: {best_params}')\n",
    "print(f'Best Cross-Validation ROC AUC Score: {best_score:.4f}')\n",
    "\n",
    "# Evaluate on the test set\n",
    "best_knn_model = grid_search.best_estimator_\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "y_pred_proba = grid_search.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "beta_2 = beta_2_score(y_test, y_pred)\n",
    "print(f'Test ROC AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}')\n",
    "print(f'Classification Report:\\n{classification_report(y_test, y_pred)}')\n",
    "print(f'f1_score: {f1}')\n",
    "print(f'beta_2: {beta_2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa732970",
   "metadata": {},
   "outputs": [],
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943d0273",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_results = evaluate_model(best_knn_model, X_test, y_test)\n",
    "log_reg_results = evaluate_model(best_log_reg_model, X_test, y_test)\n",
    "xgb_results = evaluate_model(best_xgb_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1676545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "print('Accuracy:', knn_results['acc'])\n",
    "print('Precision:', knn_results['prec'])\n",
    "print('Recall:', knn_results['rec'])\n",
    "print('F1 Score:', knn_results['f1'])\n",
    "print('beta_2',knn_results['beta_2'])\n",
    "print('Area Under Curve:', knn_results['auc'])\n",
    "print('Confusion Matrix:\\n', knn_results['cm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d6a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy:', log_reg_results['acc'])\n",
    "print('Precision:', log_reg_results['prec'])\n",
    "print('Recall:', log_reg_results['rec'])\n",
    "print('F1 Score:', log_reg_results['f1'])\n",
    "print('beta_2',log_reg_results['beta_2'])\n",
    "print('Area Under Curve:', log_reg_results['auc'])\n",
    "print('Confusion Matrix:\\n', log_reg_results['cm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4fb273",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy:', xgb_results['acc'])\n",
    "print('Precision:', xgb_results['prec'])\n",
    "print('Recall:', xgb_results['rec'])\n",
    "print('F1 Score:', xgb_results['f1'])\n",
    "print('beta_2',xgb_results['beta_2'])\n",
    "print('Area Under Curve:', xgb_results['auc'])\n",
    "print('Confusion Matrix:\\n', xgb_results['cm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0ce330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
