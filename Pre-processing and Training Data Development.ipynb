{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92b9bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b53904",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BRFSS_cleaned2.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "794178e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GeneralHealth'].fillna('Unsure', inplace = True)\n",
    "df['LastCheckup'].fillna('Unsure', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee54cc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.dropna(subset=['RaceEthnicityGroup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f118d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = {\n",
    "    'Male': 1,\n",
    "    'Female': 0\n",
    "}\n",
    "df['Sex'] = df['Sex'].map(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10f1eb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "genhealth = {\n",
    "    'Unsure': 0,\n",
    "    'Poor': 1,\n",
    "    'Fair': 2,\n",
    "    'Good': 3,\n",
    "    'Very Good': 4,\n",
    "    'Excellent': 5\n",
    "}\n",
    "\n",
    "df['GeneralHealth'] = df['GeneralHealth'].map(genhealth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65e8b575",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkup = {\n",
    "    'Never':0,\n",
    "    'Within past year (anytime less than 12 months ago)':1,\n",
    "    'Within past 2 years (1 year but less than 2 years ago)' :2,\n",
    "    'Within past 5 years (2 years but less than 5 years ago)':3,\n",
    "    '5 or more years ago': 4,\n",
    "    'Unsure' : 5\n",
    "}\n",
    "\n",
    "df['LastCheckup'] = df['LastCheckup'].map(checkup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e75fe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = {\n",
    "    'Age 18 to 24': 0,\n",
    "    'Age 25 to 29': 1,\n",
    "    'Age 30 to 34': 2,\n",
    "    'Age 35 to 39': 3,\n",
    "    'Age 40 to 44': 4,\n",
    "    'Age 45 to 49': 5,\n",
    "    'Age 50 to 54': 6,\n",
    "    'Age 55 to 59': 7,\n",
    "    'Age 60 to 64': 8,\n",
    "    'Age 65 to 69': 9,\n",
    "    'Age 70 to 74': 10,\n",
    "    'Age 75 to 79': 11,\n",
    "    'Age 80 or older': 12\n",
    "}\n",
    "\n",
    "df['AgeGroup5yrs'] = df['AgeGroup5yrs'].map(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79519568",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoked = {\n",
    "    'Never smoked': 0,\n",
    "    'Smoked': 1\n",
    "}\n",
    "\n",
    "df['Smoked'] = df['Smoked'].map(smoked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fa9a0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_no = {\n",
    "    'Yes' : 1,\n",
    "    'No' : 0\n",
    "}\n",
    "\n",
    "df['ExerciseLast30days'] = df['ExerciseLast30days'].map(yes_no)\n",
    "df['HadHeartAttack'] = df['HadHeartAttack'].map(yes_no)\n",
    "df['HadAngina'] = df['HadAngina'].map(yes_no)\n",
    "df['HadStroke'] = df['HadStroke'].map(yes_no)\n",
    "df['HadAsthma'] = df['HadAsthma'].map(yes_no)\n",
    "df['HadSkinCancer'] = df['HadSkinCancer'].map(yes_no)\n",
    "df['HadCOPD'] = df['HadCOPD'].map(yes_no)\n",
    "df['HadDepressiveDisorder'] = df['HadDepressiveDisorder'].map(yes_no)\n",
    "df['HadKidneyDisease'] = df['HadKidneyDisease'].map(yes_no)\n",
    "df['HadArthritis'] = df['HadArthritis'].map(yes_no)\n",
    "df['Deaf'] = df['Deaf'].map(yes_no)\n",
    "df['Blind'] = df['Blind'].map(yes_no)\n",
    "df['DifficultyConcentrating'] = df['DifficultyConcentrating'].map(yes_no)\n",
    "df['DifficultyDressingOrBathing'] = df['DifficultyDressingOrBathing'].map(yes_no)\n",
    "df['DifficultyAloneErrands'] = df['DifficultyAloneErrands'].map(yes_no)\n",
    "df['HeartDisease'] = df['HeartDisease'].map(yes_no)\n",
    "df['HadChestScan'] = df['HadChestScan'].map(yes_no)\n",
    "df['FluShotLast12Months'] = df['FluShotLast12Months'].map(yes_no)\n",
    "df['HadPneumoniaShot'] = df['HadPneumoniaShot'].map(yes_no)\n",
    "df['HIVRisk'] = df['HIVRisk'].map(yes_no)\n",
    "df['AlcoholLast30days'] = df['AlcoholLast30days'].map(yes_no)\n",
    "df['TestedForHIV'] = df['TestedForHIV'].map(yes_no)\n",
    "df['DifficultyWalking'] = df['DifficultyWalking'].map(yes_no)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf48068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabete = {\n",
    "    'No' : 0,\n",
    "    'Yes' : 1,\n",
    "    'No, pre-diabetes or borderline diabetes' : 0,\n",
    "    'Yes, but female told only during pregnancy' : 1\n",
    "}\n",
    "\n",
    "df['HadDiabetes'] = df['HadDiabetes'].map(diabete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feb6b490",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecig = {\n",
    "    'Never used e-cigarettes in your entire life' : 0,\n",
    "    'Not at all (right now)' : 0,\n",
    "    'Use them every day' : 1,\n",
    "    'Use them some days':1\n",
    "}\n",
    "\n",
    "df['EcigUsage'] = df['EcigUsage'].map(ecig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83faae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "tetshot = {\n",
    "    'No, did not receive any tetanus shot in the past 10 years':0,\n",
    "    'Yes, received tetanus shot but not sure what type': 1,\n",
    "    'Yes, received Tdap': 1,\n",
    "    'Yes, received tetanus shot, but not Tdap': 1\n",
    "}\n",
    "\n",
    "df['HadTetanusShot'] = df['HadTetanusShot'].map(tetshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a05d526",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid = {\n",
    "    'Tested positive using home test without health professional': 1,\n",
    "    'Yes' : 1,\n",
    "    'No' : 0\n",
    "}\n",
    "\n",
    "df['HadCovid'] = df['HadCovid'].map(covid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44a44b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "race = {\n",
    "    'White only, non-Hispanic' : 0,\n",
    "    'Black only, non-Hispanic': 1,\n",
    "    'Hispanic': 2,\n",
    "    'Asian only, non-Hispanic': 3,\n",
    "    'American Indian or Alaskan Native only, Non-Hispanic': 4,\n",
    "    'Native Hawaiian or other Pacific Islander only, Non-Hispanic': 5,\n",
    "    'Multiracial, non-Hispanic': 6\n",
    "}\n",
    "\n",
    "df['RaceEthnicityGroup'] = df['RaceEthnicityGroup'].map(race)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "364b5e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    \"Alabama\": 1,\n",
    "    \"Alaska\" : 2,\n",
    "    \"Arizona\": 3,\n",
    "    \"Arkansas\" : 4,\n",
    "    \"California\": 5,\n",
    "    \"Colorado\": 6,\n",
    "    \"Connecticut\": 7,\n",
    "    \"Delaware\": 8,\n",
    "    \"District of Columbia\": 9,\n",
    "    \"Florida\": 10,\n",
    "    \"Georgia\": 11,\n",
    "    \"Hawaii\": 12,\n",
    "    \"Idaho\": 13,\n",
    "    \"Illinois\": 14,\n",
    "    \"Indiana\": 15,\n",
    "    \"Iowa\": 16,\n",
    "    \"Kansas\": 17,\n",
    "    \"Kentucky\": 18,\n",
    "    \"Louisiana\": 19,\n",
    "    \"Maine\": 20,\n",
    "    \"Maryland\": 21,\n",
    "    \"Massachusetts\": 22,\n",
    "    \"Michigan\" : 23,\n",
    "    \"Minnesota\": 24,\n",
    "    \"Mississippi\": 25,\n",
    "    \"Missouri\": 26,\n",
    "    \"Montana\":27,\n",
    "    \"Nebraska\":28,\n",
    "    \"Nevada\":29,\n",
    "    \"New Hampshire\":30,\n",
    "    \"New Jersey\":31,\n",
    "    \"New Mexico\":32,\n",
    "    \"New York\":33,\n",
    "    \"North Carolina\":34,\n",
    "    \"North Dakota\":35,\n",
    "    \"Ohio\":36,\n",
    "    \"Oklahoma\":37,\n",
    "    \"Oregon\":38,\n",
    "    \"Pennsylvania\":39,\n",
    "    \"Rhode Island\":40,\n",
    "    \"South Carolina\":41,\n",
    "    \"South Dakota\":42,\n",
    "    \"Tennessee\":43,\n",
    "    \"Texas\":44,\n",
    "    \"Utah\":45,\n",
    "    \"Vermont\":46,\n",
    "    \"Virginia\":47,\n",
    "    \"Washington\":48,\n",
    "    \"West Virginia\":49,\n",
    "    \"Wisconsin\":50,\n",
    "    \"Wyoming\":51,\n",
    "    \"Guam\":52,\n",
    "    \"Puerto Rico\":53,\n",
    "    \"Virgin Islands\":54\n",
    "}\n",
    "\n",
    "df['State'] = df['State'].map(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e932c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_drop = ['HIVRisk',\n",
    "                'isObese',\n",
    "                'DifficultyConcentrating',\n",
    "                'HadAsthma',\n",
    "                'Blind',\n",
    "                'HadDepressiveDisorder',\n",
    "                'TestedForHIV',\n",
    "                'AlcoholLast30days',\n",
    "                'HadSkinCancer',\n",
    "                'DifficultyDressingOrBathing',\n",
    "                'FluShotLast12Months',\n",
    "                'DifficultyAloneErrands',\n",
    "                'LevelOfSmoker',\n",
    "                'HadChestScan',\n",
    "                'HadPneumoniaShot',\n",
    "                'HadTetanusShot',\n",
    "                'HadHeartAttack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a303d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = columns_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b49998df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['DrinkOccasionsPerDay'] = df['DrinkOccasionsPerDay'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f2faed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering lowest importance\n",
    "#columns_drop = ['HIVRisk', 'isObese', 'DifficultyConcentrating', 'HadAsthma', 'Blind', 'HadDepressiveDisorder', 'TestedForHIV','AlcoholLast30days','HadSkinCancer','DifficultyDressingOrBathing','FluShotLast12Months','DifficultyAloneErrands']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48874309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical_columns = ['Sex','GeneralHealth','ExerciseLast30days','LastCheckup','HadHeartAttack','HadAngina','HadStroke',\n",
    "                  #  'HadCOPD','HadKidneyDisease','HadArthritis','HadDiabetes','Deaf','DifficultyWalking',\n",
    "                  #  'EcigUsage','HadChestScan', 'HadPneumoniaShot','HadTetanusShot','HadCovid','RaceEthnicityGroup',\n",
    "                  #  'AgeGroup5yrs','LevelOfSmoker', 'Smoked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "713f72ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns =['HeartDisease'], axis = 1)\n",
    "y = df['HeartDisease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a4cd66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97c2d87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54c582f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = pd.get_dummies(X_train, columns=categorical_columns, drop_first=True)\n",
    "#X_test = pd.get_dummies(X_test, columns=categorical_columns, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8f35bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "X_train = imputer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49900795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71234, 25)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b16514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE or other techniques only to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5136570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in X_train: False\n",
      "NaNs in X_test: True\n"
     ]
    }
   ],
   "source": [
    "print(\"NaNs in X_train:\", np.any(np.isnan(X_train)))\n",
    "print(\"NaNs in X_test:\", np.any(np.isnan(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03112c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5cd8df92",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m error\n",
      "\u001b[1;31mNameError\u001b[0m: name 'error' is not defined"
     ]
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a7134ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imdan\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SimpleImputer was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08c02195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler: Accuracy = 0.9213, Recall = 0.8254\n",
      "MinMaxScaler: Accuracy = 0.9315, Recall = 0.8354\n",
      "RobustScaler: Accuracy = 0.9077, Recall = 0.7819\n",
      "MaxAbsScaler: Accuracy = 0.9273, Recall = 0.8328\n"
     ]
    }
   ],
   "source": [
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler(),\n",
    "    'MaxAbsScaler': MaxAbsScaler()\n",
    "}\n",
    "\n",
    "# Dictionary to store evaluation results\n",
    "results = {}\n",
    "\n",
    "# Evaluate each scaler\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    # Fit and transform the training data\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Train the KNN model\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    results[scaler_name] = {\n",
    "        'accuracy': report['accuracy'],\n",
    "        'recall': report['macro avg']['recall']  # Use 'macro avg' to get the average recall\n",
    "    }\n",
    "\n",
    "# Print the results\n",
    "for scaler_name, metrics in results.items():\n",
    "    print(f\"{scaler_name}: Accuracy = {metrics['accuracy']:.4f}, Recall = {metrics['recall']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a3ab011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imdan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\imdan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\imdan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\imdan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler: Accuracy = 0.9366, Recall = 0.8133, F1 Score = 0.7262, Beta=2 Score = 0.6608\n",
      "MinMaxScaler: Accuracy = 0.6892, Recall = 0.7228, F1 Score = 0.3091, Beta=2 Score = 0.4844\n",
      "RobustScaler: Accuracy = 0.9149, Recall = 0.8056, F1 Score = 0.6408, Beta=2 Score = 0.6380\n",
      "MaxAbsScaler: Accuracy = 0.9273, Recall = 0.8328, F1 Score = 0.6893, Beta=2 Score = 0.6867\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define Beta=2 score calculation\n",
    "def beta_2_score(y_true, y_pred):\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    beta = 2\n",
    "    return (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)\n",
    "\n",
    "# Evaluate each scaler\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    # Fit and transform the training data\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train the KNN model\n",
    "    log_reg = LogisticRegression(penalty='l1', solver='saga', random_state=42)\n",
    "    log_reg.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    y_pred = knn.predict(X_test_scaled)\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    accuracy = report['accuracy']\n",
    "    recall = report['macro avg']['recall']  # Use 'macro avg' to get the average recall\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    beta_2 = beta_2_score(y_test, y_pred)  # Calculate Beta=2 score\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)  # Manually compute F1 score\n",
    "   \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results[scaler_name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'beta_2_score': beta_2,\n",
    "        'precision': precision,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "# Print the results\n",
    "for scaler_name, metrics in results.items():\n",
    "    print(f\"{scaler_name}: Accuracy = {metrics['accuracy']:.4f}, Recall = {metrics['recall']:.4f}, F1 Score = {metrics['f1_score']:.4f}, Beta=2 Score = {metrics['beta_2_score']:.4f}\")\n",
    "    #print(f\"Confusion Matrix:\\n{metrics['confusion_matrix']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28766c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['HeartDisease'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "68500404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.8794521068755318\n",
      "ROC AUC Score: 0.9411020715650876\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     64641\n",
      "           1       1.00      0.70      0.82      6593\n",
      "\n",
      "    accuracy                           0.97     71234\n",
      "   macro avg       0.98      0.85      0.90     71234\n",
      "weighted avg       0.97      0.97      0.97     71234\n",
      "\n",
      "Confusion Matrix:\n",
      " [[64636     5]\n",
      " [ 1969  4624]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imdan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, classification_report, roc_auc_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume X and y are your features and target variable\n",
    "\n",
    "# Split the data\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to oversample the training data\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train the logistic regression model\n",
    "log_reg = LogisticRegression(penalty='l1', solver='saga', random_state=42)\n",
    "log_reg.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_proba = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Precision-recall curve to find the best threshold\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "# Predict with the best threshold\n",
    "y_pred_int = (y_pred_proba >= best_threshold).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Best threshold:', best_threshold)\n",
    "print('ROC AUC Score:', roc_auc_score(y_test, y_pred_proba))\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred_int))  # Changed y_pred to y_pred_int\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01c6017",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Series(y).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9929c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "y_pred_int = (y_pred_proba >= best_threshold).astype(int)\n",
    "\n",
    "print('Best threshold:', best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23202374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(knn, X_train_res, y_train_res, cv=5, scoring='roc_auc')\n",
    "print('Cross-Validation ROC AUC Scores:', cv_scores)\n",
    "print('Mean Cross-Validation ROC AUC Score:', cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9370c784",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(log_reg, X_train_res, y_train_res, cv=5, scoring='roc_auc')\n",
    "print('Cross-Validation ROC AUC Scores:', cv_scores)\n",
    "print('Mean Cross-Validation ROC AUC Score:', cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959254ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_test_pred_proba = knn.predict_proba(X_test)[:, 1]\n",
    "test_roc_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
    "print('Test ROC AUC Score:', test_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56691bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_test_pred_proba = log_reg.predict_proba(X_test)[:, 1]\n",
    "test_roc_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
    "print('Test ROC AUC Score:', test_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1111ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
